{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXtLDP0DgiCQtEKGMbOx3N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuahurd515/ai-and-data-science-work/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDmBeG9IPVmu",
        "outputId": "e67cc018-6811-40f1-9661-33fa4ae88acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7971449222085092\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import learning_curve, cross_val_score, train_test_split\n",
        "\n",
        "data = pd.read_csv(\"wdbc.data\", header=None)\n",
        "data.drop(columns=[0], inplace=True)\n",
        "\n",
        "data[1] = data[1].map({'M': 1, 'B': 0})\n",
        "\n",
        "X_train = data.iloc[:-99, 1:]\n",
        "y_train = data.iloc[:-99, 0]\n",
        "X_test = data.iloc[-99:, 1:]\n",
        "y_test = data.iloc[-99:, 0]\n",
        "\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data.drop(\"target\", axis=1), data[\"target\"], test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, max_features=None, random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "accTrain = np.mean(cross_val_score(rf, X_train, y_train, cv = 5))\n",
        "\n",
        "print(\"Accuracy: \", accTrain)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based off of this, the decision forest seen above seems to have an accuracy rate of about 80 percent, which is around 10 pecent less than the SVM and MLP model that I had previously trained on in project 2, however, changing some of the parameters is able to give a much better estimate."
      ],
      "metadata": {
        "id": "VuiiDWjtRtuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=500, max_features=None, random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "accTrain = np.mean(cross_val_score(rf, X_train, y_train, cv = 5))\n",
        "\n",
        "print(\"Accuracy: \", accTrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYxzB47BSNij",
        "outputId": "62a17ef6-012e-4ff4-8366-5e5f7d5f9d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8013035179325667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from above, increasing the number of trees from 100, to 500 does not increase the accuracy as much, so chaning the number of trees without changing the number if features seems to have very little to no effect of the accuracy of this model."
      ],
      "metadata": {
        "id": "oB6iceMbSpj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=100, max_features=3, random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "accTrain = np.mean(cross_val_score(rf, X_train, y_train, cv = 5))\n",
        "\n",
        "print(\"Accuracy: \", accTrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THhmq-nxS5F5",
        "outputId": "d2390cc3-7cc2-4d39-9ea4-415f00b840c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8308295701647872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from here, changing the number of features by itself seems to have a little more of an accurate prediction, but only by around 3 percent"
      ],
      "metadata": {
        "id": "xrXSWbx8TeV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=500, max_features=3, random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "accTrain = np.mean(cross_val_score(rf, X_train, y_train, cv = 5))\n",
        "\n",
        "print(\"Accuracy: \", accTrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ghl-zcqTnPS",
        "outputId": "86dddd4f-fbee-44cc-ebd8-5167561d5772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8326665895646463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And as you can see from above, the accuracy is still about the same when you add more trees and a different amount of max features, so changing them together can be tricky to get the highest accuracy that can possibly be acheived."
      ],
      "metadata": {
        "id": "yxkxddDMTtI6"
      }
    }
  ]
}